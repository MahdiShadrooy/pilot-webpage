---
layout: default
title: Home
---

**Spring 2026**  
Sharif University of Technology  

**Instructor**  
Dr. Motahari 

---

## Course Overview

Machine learning is fundamentally a statistical discipline concerned with function approximation under uncertainty.

Statistical Machine Learning develops learning as a problem of statistical inference and risk minimization rather than a collection of algorithms. The course emphasizes modeling assumptions, complexity control, and generalization, treating each method as an instance of a unified framework defined by a function class, loss function, and mechanism for controlling overfitting. Ridge regression, Lasso, SVMs, trees, boosting, and neural networks are presented as different answers to the same fundamental question: how can we control complexity to generalize from finite data? The goal is not to apply methods mechanically, but to understand why they should work before using them.

We emphasize principles over software and derivations over recipes.

---
**References**

- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning: with Applications in Python*. Springer.

- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd ed.). Springer.

**Extra Resources**

- [CS 189/289A: Introduction to Machine Learning](https://people.eecs.berkeley.edu/~jrs/189/) – University of California, Berkeley.
- 

---

## Intended Audience

Senior undergraduate students (6th semester and above) and graduate students.

**Prerequisites**
- Probability theory  
- Linear algebra  
- Multivariable calculus  

---

## Learning Objectives

By the end of this course, students will be able to:

- Formulate supervised learning as risk minimization  
- Analyze modeling assumptions explicitly  
- Reason about bias–variance and generalization  
- Apply regularization and complexity control principles  
- Critically evaluate machine learning methods  
